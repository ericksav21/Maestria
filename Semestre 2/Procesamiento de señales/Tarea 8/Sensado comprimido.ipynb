{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alumno: Erick Salvador Alvarez Valencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos interés en muestrear una señal coseno descrita de la siguiente forma: $$cos(w_0n) = \\frac{1}{2}[e^{i2 \\pi f_0n} + e^{-i2 \\pi f_0n}]$$ Dicho interés es causado ya que se quiere realizar el muestreo de la señal por debajo de la frecuencia de muestreo que nos dice el teorema de Nyquist.\n",
    "\n",
    "Podemos definir a la señal que queremos muestrear como $\\vec{f} \\in R^N$ y la señal que quremos muestrear como $\\vec{g} \\in R^M$ con $M << N$. La problemática es que el núḿero de muestras que tenemos generaremos una representación rala de la señal y si queremos aplicar alguna técnica como interpolación sabemos que existen familias de polinomios muy grandes que generarían señales muy distintas pero que pasarían por los puntos de la muestra.\n",
    "\n",
    "Otra manera de hacer el muestreo es usando la técnica de mínimos cuadrados, la cual genera una aproximación a la señal basada en un modelo previamente dado, pero esto generaría una situación muy parecida a la anterior.\n",
    "\n",
    "La forma en que se ataca al problema es partiendo de la transformada de Fourier: $$f_nm = \\frac{1}{N} \\sum_{k = 0}^{N - 1} F_k e^{\\frac{i2 \\pi kn}{N}m}$$ donde $F_k \\in \\vec{F}$. De la misma forma podemos ver a la función que queremos muestrear como: $$g_m = \\frac{<\\vec{S}, \\vec{F}>}{N}$$.\n",
    "\n",
    "La idea es generar esto como un problema de optimización, en donde queremos maximizar el número de ceros que nos generaría la transformada de Fourier, para lo cual lo planteamos primeramente en su forma matricial:\n",
    "\n",
    "$$\\vec{g} = A \\vec{F}$$ con $A \\in R^{M x N}$ y $F \\in R^{N x N}$\n",
    "\n",
    "Por otro lado $$\\vec{F} = B \\vec{f}$$ con $B \\in R^{N x N}$\n",
    "\n",
    "$$A = [\\vec{S}^{n0}, \\vec{S}^{n1}, \\vec{S}^{n02}, ..., \\vec{S}^{nm}]^T$$\n",
    "$$B = [^0\\vec{S}^{T}, ^1\\vec{S}^{T}, ..., ^{M - 1}\\vec{S}^{T}]^T$$\n",
    "\n",
    "Para el problema de maximización podemos usar la norma cero, la cual es vista como una pseudonorma: $$||X||_0 = \\text{El número de ceros que hay en X}$$.\n",
    "\n",
    "Describiendo el problema de optimización como: $$max_{\\vec{F}} ||\\vec{F}||_0$$ s.a. $A \\vec{f} = \\vec{g}$.\n",
    "\n",
    "Finalmente podemos convertir el problema de optimización en uno convexo usando una norma convexa como la 1: $$||X||_1 = r$$ La cual se puede ver como un rombo, y el punto óptimo es tangencial a una recta. Para resolver esto se requiere de un algoritmo de optimización convexa con restricciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
